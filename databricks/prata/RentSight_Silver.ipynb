{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "86e9c008-28a4-4c34-a346-a8a80a543c57",
          "showTitle": true,
          "tableResultSettingsMap": {},
          "title": "Intro"
        }
      },
      "source": [
        "# üì¶ RentSight ‚Äî Pipeline em camadas (Databricks / Spark)\n",
        "\n",
        "Esses notebooks s√£o **exemplos read-only** que reproduzem a l√≥gica do seu orquestrador `run_pipeline.py`, s√≥ que em **PySpark**.\n",
        "\n",
        "Camadas:\n",
        "- **Bronze**: ingest√£o do CSV (tudo como string) e escrita em Parquet.\n",
        "- **Silver**: sele√ß√£o de colunas, casts seguros, normaliza√ß√£o/simula√ß√£o de `room_type`, e escrita em Parquet.\n",
        "- **Gold**: agrega√ß√µes anal√≠ticas e escrita das tabelas finais em Parquet.\n",
        "\n",
        "‚úÖ Dica: voc√™ pode rodar cada notebook isolado (ele l√™ da camada anterior pelo caminho padr√£o).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8873f235-fc64-401b-b299-5fb78c7c33a1",
          "showTitle": false,
          "tableResultSettingsMap": {}
        }
      },
      "source": [
        "## ü•à SILVER ‚Äî Curadoria + casts seguros + simula√ß√£o de `room_type`\n",
        "\n",
        "Reproduz a l√≥gica do seu `silver(df_raw)`:\n",
        "- seleciona colunas\n",
        "- cria `id` sequencial (row_number)\n",
        "- casts seguros (invalid ‚Üí null)\n",
        "- normaliza `room_type` e **simula** valores ausentes com rand(seed=42)\n",
        "- remove `room_type` original e mant√©m `room_type_simulated`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e5d4782b-68a1-4375-88f5-9810bba8c6df",
          "showTitle": false,
          "tableResultSettingsMap": {}
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "bronze_in_path = '/Volumes/rentsight/bronze/listings_bronze_rj'\n",
        "silver_out_path = '/Volumes/rentsight/silver/listings_silver_rj'\n",
        "\n",
        "print('BRONZE IN:', bronze_in_path)\n",
        "print('SILVER OUT:', silver_out_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e1c2d94c-450b-41a2-8fd7-ddc4341726af",
          "showTitle": false,
          "tableResultSettingsMap": {}
        }
      },
      "outputs": [],
      "source": [
        "df_raw = spark.read.parquet(bronze_in_path)\n",
        "print('Rows:', df_raw.count())\n",
        "display(df_raw.limit(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f25bf3c5-85a9-4e10-89ca-0382dba88965",
          "showTitle": false,
          "tableResultSettingsMap": {}
        }
      },
      "outputs": [],
      "source": [
        "cols = [\n",
        "    'id', 'neighbourhood', 'latitude', 'longitude', 'room_type', 'price',\n",
        "    'minimum_nights', 'number_of_reviews', 'last_review',\n",
        "    'reviews_per_month', 'availability_365'\n",
        "]\n",
        "\n",
        "missing = [c for c in cols if c not in df_raw.columns]\n",
        "if missing:\n",
        "    raise Exception(f'Colunas ausentes no RAW/BRONZE: {missing}')\n",
        "\n",
        "df = df_raw.select(*cols)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "7df5e3b1-55b4-4922-b50e-88edd19e0527",
          "showTitle": false,
          "tableResultSettingsMap": {}
        }
      },
      "outputs": [],
      "source": [
        "w = Window.orderBy(F.monotonically_increasing_id())\n",
        "df = df.withColumn('id', F.row_number().over(w).cast('long'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "76d02308-40d2-4361-8e5b-941c96d32873",
          "showTitle": false,
          "tableResultSettingsMap": {}
        }
      },
      "outputs": [],
      "source": [
        "df = (\n",
        "    df\n",
        "    .withColumn('price', F.col('price').cast('double'))\n",
        "    .withColumn('minimum_nights', F.col('minimum_nights').cast('int'))\n",
        "    .withColumn('number_of_reviews', F.col('number_of_reviews').cast('int'))\n",
        "    .withColumn('last_review', F.to_date(F.col('last_review')))\n",
        "    .withColumn('reviews_per_month', F.col('reviews_per_month').cast('double'))\n",
        "    .withColumn('availability_365', F.col('availability_365').cast('int'))\n",
        "    .withColumn('latitude', F.col('latitude').cast('double'))\n",
        "    .withColumn('longitude', F.col('longitude').cast('double'))\n",
        "    .withColumn('room_type', F.col('room_type').cast('string'))\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "aaeb8ceb-1fdc-4814-9834-ba82bec59c18",
          "showTitle": false,
          "tableResultSettingsMap": {}
        }
      },
      "outputs": [],
      "source": [
        "norm = F.lower(F.trim(F.col('room_type')))\n",
        "\n",
        "clean = (\n",
        "    F.when(norm == F.lit('entire home/apt'), F.lit('Entire home/apt'))\n",
        "     .when(norm == F.lit('private room'), F.lit('Private room'))\n",
        "     .when(norm == F.lit('shared room'), F.lit('Shared room'))\n",
        "     .when(norm == F.lit('hotel room'), F.lit('Hotel room'))\n",
        ")\n",
        "\n",
        "r = F.rand(seed=42)\n",
        "\n",
        "simulated_when_missing = (\n",
        "    F.when(r < 0.25, F.lit('Entire home/apt'))\n",
        "     .when(r < 0.50, F.lit('Private room'))\n",
        "     .when(r < 0.75, F.lit('Shared room'))\n",
        "     .otherwise(F.lit('Hotel room'))\n",
        ")\n",
        "\n",
        "df = df.withColumn(\n",
        "    'room_type_simulated',\n",
        "    F.coalesce(clean, simulated_when_missing).cast('string')\n",
        ")\n",
        "\n",
        "df = df.drop('room_type')\n",
        "\n",
        "display(df.limit(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "639a1b7d-919d-4f50-a43a-7f3a6fd92330",
          "showTitle": false,
          "tableResultSettingsMap": {}
        }
      },
      "outputs": [],
      "source": [
        "(\n",
        "    df\n",
        "    .write\n",
        "    .mode('overwrite')\n",
        "    .parquet(silver_out_path)\n",
        ")\n",
        "print('‚úÖ Silver gravado em:', silver_out_path)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
